{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vt337/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "/home/vt337/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "from denoising_diffusion_pytorch import Unet1D, GaussianDiffusion1D, Trainer1D, Dataset1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/r77-mini-data-fortnight/input\n"
     ]
    }
   ],
   "source": [
    "proj_dir = Path(\"..\") / \"Data/r77-mini-data-fortnight\"\n",
    "print(proj_dir.joinpath(\"input\"))\n",
    "\n",
    "data_dir = proj_dir\n",
    "input_dir = data_dir.joinpath(\"input\")\n",
    "fixed_input_dir = input_dir.joinpath(\"fixed\")\n",
    "temporal_input_dir = input_dir.joinpath(\"temporal\")\n",
    "target_dir = data_dir.joinpath(\"target\")\n",
    "fixed_target_dir = target_dir.joinpath(\"fixed\")\n",
    "temporal_target_dir = target_dir.joinpath(\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 70, 100, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(temporal_target_dir.iterdir())\n",
    "\n",
    "\n",
    "index_dir = Path(\"..\")/\"Index\"\n",
    "files_index = list(index_dir.iterdir())\n",
    "indices = np.load(files_index[0]).squeeze()\n",
    "\n",
    "#First hour of data\n",
    "index = indices[0]\n",
    "tt = np.load(files[index]).squeeze()\n",
    "tt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_ti = list(temporal_input_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for j in range(360):\n",
    "    index = indices[j]\n",
    "\n",
    "    tt = np.load(files[index]).squeeze()\n",
    "    tt = np.transpose(tt, (0, 2, 3, 1))[:, :, :, :64]  #shape: (144, 100, 3, 64)\n",
    "\n",
    "    ti = np.load(files_ti[index]).squeeze()\n",
    "    ti = np.transpose(ti, (0, 2, 1))[:, :, :64]  #shape: (144, 3, 64)\n",
    "\n",
    "    #ensure ti has the same second dimension as tt\n",
    "    ti_expanded = np.repeat(ti[:, None, :, :], tt.shape[1], axis=1)  #shape: (144, 100, 3, 64)\n",
    "\n",
    "    #calculate diff and reshape\n",
    "    diff_data = tt - ti_expanded  #shape: (144, 100, 3, 64)\n",
    "    reshaped_tt = diff_data.reshape(-1, 3, 64)  #shape: (14400, 3, 64)\n",
    "\n",
    "    data.append(reshaped_tt)\n",
    "\n",
    "\n",
    "data = np.concatenate(data).reshape(-1, 3, 64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5184000, 3, 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(vector):\n",
    "    min_val = np.min(vector)\n",
    "    max_val = np.max(vector)\n",
    "    normalised_vector = (vector - min_val) / (max_val - min_val)\n",
    "    return normalised_vector, min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = normalise(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vt337/.local/lib/python3.10/site-packages/accelerate/accelerator.py:447: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(split_batches=True)\n",
      "  warnings.warn(\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:00<00:00, 133.44it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:00<00:00, 146.90it/s]\n",
      "sampling loop time step: 100%|██████████| 100/100 [00:00<00:00, 139.98it/s]\n",
      "loss: 0.0064: 100%|██████████| 1000/1000 [00:57<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Unet1D(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels = 3\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion1D(\n",
    "    model,\n",
    "    seq_length = 64,\n",
    "    timesteps = 100,\n",
    "    objective = 'pred_v'\n",
    ")\n",
    "\n",
    "training_seq =  torch.from_numpy(training_data)\n",
    "\n",
    "trainer = Trainer1D(\n",
    "    diffusion,\n",
    "    dataset = training_seq,\n",
    "    train_batch_size = 10, #set batch size here (take 100 samples, one grid)\n",
    "    train_lr = 1e-4,\n",
    "    train_num_steps = 1000,         # total training steps (1000)\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    amp = True,                       # turn on mixed precision\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# after a lot of training\n",
    "\n",
    "sampled_diff_seq = diffusion.sample(batch_size = 10000)\n",
    "sampled_diff_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|██████████| 100/100 [00:23<00:00,  4.26it/s]\n"
     ]
    }
   ],
   "source": [
    "sampled_diff_seq = diffusion.sample(batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sampled_diff_seq.cpu().numpy()\n",
    "folder = 'Sample_diffs_B'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "file_path = os.path.join(folder, 'sample.npy')\n",
    "np.save(file_path, sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
